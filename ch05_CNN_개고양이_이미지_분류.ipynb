{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch05.CNN_개고양이 이미지 분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/fBIcBekMOtvcQ62P2D20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilmechaJu/-Base-Line-CNN/blob/main/ch05_CNN_%EA%B0%9C%EA%B3%A0%EC%96%91%EC%9D%B4_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNimB3HIF82K",
        "outputId": "3eabc521-85e8-4e11-f681-b8c8b2d530a7"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 7965854899137429876, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14509932544\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 5774420350831609736\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQrr6IywERjh",
        "outputId": "1cdb3e1f-413c-4176-d447-48034092f342"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# 훈련 데이터는 Cats vs Dogs 데이터 셋을 사용합니다.\n",
        "# 훈련 데이터의 다운로드와 압축해제는 아래 코드를 사용하면 됩니다.\n",
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "!unzip -q kagglecatsanddogs_3367a.zip\n",
        "\n",
        "#시험 데이터는 Oxford-IIIT Pet 데이터 세트를 사용합니다. 각 클래스에 대해 약 200개의 이미지가 포함된 37개의 애완 동물 데이터 세트입니다.\n",
        "#시험 데이터의 다운로드와 압축해제는 아래 코드를 사용하면 됩니다.\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!tar -xzf images.tar.gz\n",
        "!cd images ; mkdir img ; mv ./*jpg ./img\n",
        "\n",
        "num_skipped = 0\n",
        "for folder_name in (\"Cat\", \"Dog\"):\n",
        "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "\n",
        "print(\"Deleted %d images\" % num_skipped)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "num_skipped = 0\n",
        "\n",
        "folder_path = os.path.join(\"images\", \"img\")\n",
        "for fname in os.listdir(folder_path):\n",
        "    fpath = os.path.join(folder_path, fname)\n",
        "    try:\n",
        "        fobj = open(fpath, \"rb\")\n",
        "        is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
        "    finally:\n",
        "        fobj.close()\n",
        "\n",
        "    if not is_jfif:\n",
        "        num_skipped += 1\n",
        "        # Delete corrupted image\n",
        "        os.remove(fpath)\n",
        "\n",
        "print(\"Deleted %d images\" % num_skipped)\n",
        "\n",
        "text_ds = ImageDataGenerator(rescale=1./255)\n",
        "# validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_ds = text_ds.flow_from_directory(\n",
        "    \"./images\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=32)\n",
        "val_ds = val_ds.prefetch(buffer_size=32)\n",
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Image augmentation block\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")\n",
        "\n",
        "\n",
        "y_pred = (np.expand_dims(test_ds.classes, axis=1).ravel()).astype(int)\n",
        "# y_pred = (model.predict(text_ds) > 0.5).astype(\"int32\")\n",
        "np.savetxt('y_pred.csv', y_pred, fmt='%i')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  786M  100  786M    0     0   176M      0  0:00:04  0:00:04 --:--:--  181M\n",
            "--2021-07-22 17:30:46--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791918971 (755M) [application/x-gzip]\n",
            "Saving to: ‘images.tar.gz’\n",
            "\n",
            "images.tar.gz       100%[===================>] 755.23M  34.6MB/s    in 22s     \n",
            "\n",
            "2021-07-22 17:31:09 (33.8 MB/s) - ‘images.tar.gz’ saved [791918971/791918971]\n",
            "\n",
            "Deleted 1590 images\n",
            "Found 23410 files belonging to 2 classes.\n",
            "Using 18728 files for training.\n",
            "Found 23410 files belonging to 2 classes.\n",
            "Using 4682 files for validation.\n",
            "Deleted 30 images\n",
            "Found 7360 images belonging to 1 classes.\n",
            "Epoch 1/20\n",
            "586/586 [==============================] - 150s 195ms/step - loss: 0.6055 - accuracy: 0.6828 - val_loss: 0.6526 - val_accuracy: 0.6587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "586/586 [==============================] - 113s 192ms/step - loss: 0.4326 - accuracy: 0.8007 - val_loss: 0.4275 - val_accuracy: 0.8039\n",
            "Epoch 3/20\n",
            "586/586 [==============================] - 113s 192ms/step - loss: 0.3532 - accuracy: 0.8447 - val_loss: 0.4211 - val_accuracy: 0.8039\n",
            "Epoch 4/20\n",
            "586/586 [==============================] - 113s 192ms/step - loss: 0.3032 - accuracy: 0.8690 - val_loss: 0.3099 - val_accuracy: 0.8676\n",
            "Epoch 5/20\n",
            "586/586 [==============================] - 112s 191ms/step - loss: 0.2666 - accuracy: 0.8884 - val_loss: 0.3032 - val_accuracy: 0.8672\n",
            "Epoch 6/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.2406 - accuracy: 0.8988 - val_loss: 0.2172 - val_accuracy: 0.9094\n",
            "Epoch 7/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.2145 - accuracy: 0.9096 - val_loss: 0.2708 - val_accuracy: 0.8783\n",
            "Epoch 8/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1981 - accuracy: 0.9184 - val_loss: 0.4417 - val_accuracy: 0.8191\n",
            "Epoch 9/20\n",
            "586/586 [==============================] - 111s 189ms/step - loss: 0.1897 - accuracy: 0.9207 - val_loss: 0.2279 - val_accuracy: 0.9015\n",
            "Epoch 10/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1751 - accuracy: 0.9274 - val_loss: 0.2414 - val_accuracy: 0.8932\n",
            "Epoch 11/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1715 - accuracy: 0.9301 - val_loss: 0.2007 - val_accuracy: 0.9165\n",
            "Epoch 12/20\n",
            "586/586 [==============================] - 111s 189ms/step - loss: 0.1640 - accuracy: 0.9326 - val_loss: 0.1982 - val_accuracy: 0.9208\n",
            "Epoch 13/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1552 - accuracy: 0.9369 - val_loss: 0.2785 - val_accuracy: 0.8930\n",
            "Epoch 14/20\n",
            "586/586 [==============================] - 112s 191ms/step - loss: 0.1469 - accuracy: 0.9410 - val_loss: 0.2043 - val_accuracy: 0.9101\n",
            "Epoch 15/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1460 - accuracy: 0.9408 - val_loss: 0.1414 - val_accuracy: 0.9430\n",
            "Epoch 16/20\n",
            "586/586 [==============================] - 111s 189ms/step - loss: 0.1383 - accuracy: 0.9443 - val_loss: 0.1709 - val_accuracy: 0.9327\n",
            "Epoch 17/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1338 - accuracy: 0.9454 - val_loss: 0.1325 - val_accuracy: 0.9438\n",
            "Epoch 18/20\n",
            "586/586 [==============================] - 112s 191ms/step - loss: 0.1281 - accuracy: 0.9471 - val_loss: 0.1395 - val_accuracy: 0.9438\n",
            "Epoch 19/20\n",
            "586/586 [==============================] - 112s 190ms/step - loss: 0.1208 - accuracy: 0.9511 - val_loss: 0.1341 - val_accuracy: 0.9445\n",
            "Epoch 20/20\n",
            "586/586 [==============================] - 111s 190ms/step - loss: 0.1225 - accuracy: 0.9506 - val_loss: 0.1339 - val_accuracy: 0.9464\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}